{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectified Flow Inference\n",
    "\n",
    "Load a checkpoint and sample using `rectified_flow_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb36644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os \n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "project_root = Path.cwd()\n",
    "if project_root.name == 'visualize':\n",
    "    project_root = project_root.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Clear Jupyter's argv to avoid argparse conflicts\n",
    "if hasattr(sys, 'argv'):\n",
    "    original_argv = sys.argv.copy()\n",
    "    sys.argv = [sys.argv[0]]\n",
    "\n",
    "\n",
    "from datawrapper.datawrapper import _coerce_matlab_text, _normalize_tensor\n",
    "from datawrapper.simple_tokenizer import SimpleTokenizer\n",
    "from datawrapper.warpper_utils import interpolate_to_target_width, resize_512\n",
    "from model.listfm_it import load_from_ckpt\n",
    "from core_funcs import rectified_flow_sample\n",
    "from common.metric import calculate_psnr, calculate_ssim\n",
    "\n",
    "tokenizer = SimpleTokenizer()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d4526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-04 21:39:43 \u001b[32m\u001b[1m[SUCCESS]\u001b[0m Checkpoint loaded successfully.\n",
      "2026-02-04 21:39:43 \u001b[34m\u001b[1m[DEBUG]\u001b[0m Width check success\n",
      "2026-02-04 21:39:43 \u001b[34m\u001b[1m[DEBUG]\u001b[0m Head check success\n",
      "2026-02-04 21:39:43 \u001b[34m\u001b[1m[DEBUG]\u001b[0m BPE file exists.\n",
      "2026-02-04 21:39:45 \u001b[34m\u001b[1m[DEBUG]\u001b[0m QC start.\n",
      "2026-02-04 21:39:45 \u001b[34m\u001b[1m[DEBUG]\u001b[0m Image size: torch.Size([2, 1, 512, 512])\n",
      "2026-02-04 21:39:45 \u001b[34m\u001b[1m[DEBUG]\u001b[0m Text size: torch.Size([2, 1536])\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m img_full_feature size: torch.Size([2, 1025, 512])\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m text_full_feature size: torch.Size([2, 1536, 512])\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m img mean std max min: 0.0458 1.1452 22.4575 -5.8304\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m text mean std max min: 0.0711 1.1340 22.2235 -2.0162\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m stack_feature[0] size: torch.Size([2, 64, 512, 512])\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m stack_feature[1] size: torch.Size([2, 128, 256, 256])\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m stack_feature[2] size: torch.Size([2, 256, 128, 128])\n",
      "2026-02-04 21:39:48 \u001b[34m\u001b[1m[DEBUG]\u001b[0m stack_feature[3] size: torch.Size([2, 512, 64, 64])\n",
      "2026-02-04 21:39:49 \u001b[34m\u001b[1m[DEBUG]\u001b[0m recon_img size: torch.Size([2, 1, 512, 512])\n",
      "2026-02-04 21:39:49 \u001b[34m\u001b[1m[DEBUG]\u001b[0m Reconstructed image size matches input image size.\n",
      "2026-02-04 21:39:49 \u001b[34m\u001b[1m[DEBUG]\u001b[0m QC success.\n",
      "2026-02-04 21:39:49 \u001b[32m\u001b[1m[SUCCESS]\u001b[0m Model state dict loaded successfully.\n",
      "loaded /home/intern4/fm2026/fm_flow/code_it/logs/00075_train/checkpoints/checkpoint_20.ckpt\n"
     ]
    }
   ],
   "source": [
    "run_idx = 75\n",
    "run_ep = 20\n",
    "\n",
    "# use best checkpoint for now\n",
    "# ckpt_path = Path(f\"/home/intern2/fm2026/fm_flow/code_it/logs/{run_idx:05d}_train/checkpoints/checkpoint_best.ckpt\")\n",
    "ckpt_path = Path(f\"/home/intern4/fm2026/fm_flow/code_it/logs/{run_idx:05d}_train/checkpoints/checkpoint_{run_ep}.ckpt\")\n",
    "data_root = Path(\"/fast_storage/intern/data/instruction_tuning/brats_acceleration_crossmodal_mat\")\n",
    "# sample_path = data_root / \"val\"\n",
    "sample_path = data_root\n",
    "\n",
    "model = load_from_ckpt(ckpt_path=ckpt_path, from_scratch=False, use_vision_decoder=True, use_vision_decoder_weights=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(\"loaded\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede901ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample brats_00525_t2_R2_to_t1_s085_000124.mat\n",
      "instruction: Reconstruct this mri image\n"
     ]
    }
   ],
   "source": [
    "# Pick one sample\n",
    "files = sorted(sample_path.glob(\"*.mat\"))\n",
    "assert files, f\"no .mat files in {sample_path}\"\n",
    "mat_path = random.choice(files)\n",
    "# mat_path = files[10]\n",
    "data = loadmat(mat_path)\n",
    "\n",
    "img = torch.from_numpy(data[\"image\"]).unsqueeze(0).unsqueeze(0).float()\n",
    "label = torch.from_numpy(data[\"label\"]).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "img = interpolate_to_target_width(img, target_size=512)\n",
    "img = resize_512(img)\n",
    "label = resize_512(interpolate_to_target_width(label, target_size=512))\n",
    "\n",
    "img = _normalize_tensor(img)\n",
    "label = _normalize_tensor(label)\n",
    "\n",
    "text_raw = _coerce_matlab_text(data[\"text\"][0][0])\n",
    "# instr_raw = _coerce_matlab_text(data[\"instruction\"][0][0])\n",
    "instr_raw = \"Reconstruct this mri image\"\n",
    "\n",
    "text = tokenizer.tokenize(text_raw, context_length=1536).squeeze().unsqueeze(0)\n",
    "instruction = tokenizer.tokenize(instr_raw, context_length=64).squeeze().unsqueeze(0)\n",
    "\n",
    "img = img.to(device)\n",
    "label = label.to(device)\n",
    "text = text.to(device)\n",
    "instruction = instruction.to(device)\n",
    "label_2 = label.clone()\n",
    "label_exp = label.clone()\n",
    "\n",
    "print(\"sample\", mat_path.name)\n",
    "# print(\"text:\", text_raw)\n",
    "print(\"instruction:\", instr_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47d546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape: (1, 1, 512, 512)\n",
      "label shape: (1, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = rectified_flow_sample(model=model, img=img, text=text, instruction=instruction)\n",
    "    # out_oneshot = rectified_flow_sample(model=model, img=img, text=text, instruction=instruction, steps=1)\n",
    "\n",
    "print(\"out shape:\", tuple(out.shape))\n",
    "print(\"label shape:\", tuple(label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e72ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr: 21.413742065429688\n",
      "ssim: 0.5630778074264526\n",
      "mse: 0.2960965931415558\n"
     ]
    }
   ],
   "source": [
    "# Metric check (PSNR, SSIM, MSE)\n",
    "psnr = calculate_psnr(label, out)\n",
    "ssim = calculate_ssim(label, out)\n",
    "print(\"psnr:\", psnr.item())\n",
    "print(\"ssim:\", ssim.item())\n",
    "\n",
    "# psnr_oneshot = calculate_psnr(label, out_oneshot)\n",
    "# ssim_oneshot = calculate_ssim(label, out_oneshot)\n",
    "# print(\"oneshot psnr:\", psnr_oneshot.item())\n",
    "# print(\"oneshot ssim:\", ssim_oneshot.item())\n",
    "\n",
    "mse = torch.mean((out.detach().cpu() - label.detach().cpu()) ** 2).item()\n",
    "print(\"mse:\", mse)\n",
    "# mse_oneshot = torch.mean((out_oneshot.detach().cpu() - label.detach().cpu()) ** 2).item()\n",
    "# print(\"oneshot mse:\", mse_oneshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8863084",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# plot input, output, label\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28minput\u001b[39m = img.squeeze().detach().cpu().numpy()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m out = \u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m().cpu().numpy()\n\u001b[32m      4\u001b[39m label = label.squeeze().detach().cpu().numpy()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# out_oneshot = out_oneshot.squeeze().detach().cpu().numpy()\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "# plot input, output, label\n",
    "input = img.squeeze().detach().cpu().numpy()\n",
    "out = out.squeeze().detach().cpu().numpy()\n",
    "label = label.squeeze().detach().cpu().numpy()\n",
    "# out_oneshot = out_oneshot.squeeze().detach().cpu().numpy()\n",
    "\n",
    "x1, x2, y1, y2 = 20, -20, 20, -20\n",
    "\n",
    "\n",
    "print(f\"input: {input.min(), input.max(), input.mean(), input.std()}\")\n",
    "print(f\"out: {out.min(), out.max(), out.mean(), out.std()}\")\n",
    "print(f\"label: {label.min(), label.max(), label.mean(), label.std()}\")\n",
    "\n",
    "vmin_input = np.percentile(input, 0.5)\n",
    "vmax_input = np.percentile(input, 99.5)\n",
    "vmin_out = np.percentile(label, 0.5)\n",
    "vmax_out = np.percentile(label, 99.5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(input[x1:x2, y1:y2], cmap=\"gray\", vmin=vmin_input, vmax=vmax_input)\n",
    "plt.title(\"Input\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(out[x1:x2, y1:y2], cmap=\"gray\", vmin=vmin_out, vmax=vmax_out)\n",
    "plt.title(\"Output\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(label[x1:x2, y1:y2], cmap=\"gray\", vmin=vmin_out, vmax=vmax_out)\n",
    "plt.title(\"Label\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 samples...\n",
      "Output directory: /home/intern4/fm2026/fm_flow/code_it/logs/00075_train/inference/ep_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:42<00:00, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference complete!\n",
      "Mean PSNR: 20.61 +/- 2.30\n",
      "Mean SSIM: 0.5339 +/- 0.2682\n",
      "Mean MSE: 0.328728 +/- 0.271009\n",
      "Results saved to: /home/intern4/fm2026/fm_flow/code_it/logs/00075_train/inference/ep_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Inference All and Save as .mat\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.io import savemat\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "run_idx = 75\n",
    "run_ep = 20\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(f\"/home/intern4/fm2026/fm_flow/code_it/logs/{run_idx:05d}_train/inference/ep_{run_ep}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "files = sorted(sample_path.glob(\"*.mat\"))\n",
    "assert files, f\"no .mat files in {sample_path}\"\n",
    "files = files[:10]\n",
    "\n",
    "print(f\"Processing {len(files)} samples...\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "results = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, mat_path in enumerate(tqdm(files)):\n",
    "        try:\n",
    "            data = loadmat(mat_path)\n",
    "            \n",
    "            img = torch.from_numpy(data[\"image\"]).unsqueeze(0).unsqueeze(0).float()\n",
    "            label = torch.from_numpy(data[\"label\"]).unsqueeze(0).unsqueeze(0).float()\n",
    "            \n",
    "            img = interpolate_to_target_width(img, target_size=512)\n",
    "            img = resize_512(img)\n",
    "            label = resize_512(interpolate_to_target_width(label, target_size=512))\n",
    "            \n",
    "            img = _normalize_tensor(img)\n",
    "            label = _normalize_tensor(label)\n",
    "            \n",
    "            text_raw = _coerce_matlab_text(data[\"text\"][0][0])\n",
    "            instr_raw = _coerce_matlab_text(data[\"instruction\"][0][0])\n",
    "            \n",
    "            text = tokenizer.tokenize(text_raw, context_length=1536).squeeze().unsqueeze(0)\n",
    "            instruction = tokenizer.tokenize(instr_raw, context_length=64).squeeze().unsqueeze(0)\n",
    "            \n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            text = text.to(device)\n",
    "            instruction = instruction.to(device)\n",
    "            \n",
    "            # Inference\n",
    "            out = rectified_flow_sample(model=model, img=img, text=text, instruction=instruction)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            psnr = calculate_psnr(label, out)\n",
    "            ssim = calculate_ssim(label, out)\n",
    "            mse = torch.mean((out.detach().cpu() - label.detach().cpu()) ** 2)\n",
    "            \n",
    "            # Convert to numpy\n",
    "            img_np = img.squeeze().detach().cpu().numpy()\n",
    "            out_np = out.squeeze().detach().cpu().numpy()\n",
    "            label_np = label.squeeze().detach().cpu().numpy()\n",
    "            \n",
    "            # Save as .mat file\n",
    "            out_mat_path = output_dir / f\"{mat_path.stem}_result.mat\"\n",
    "            savemat(str(out_mat_path), {\n",
    "                'input': img_np,\n",
    "                'out': out_np,\n",
    "                'label': label_np,\n",
    "                'instruction': instr_raw,\n",
    "                'psnr': psnr.item(),\n",
    "                'ssim': ssim.item(),\n",
    "                'mse': mse.item()\n",
    "            })\n",
    "            \n",
    "            # Store metrics\n",
    "            result = {\n",
    "                \"filename\": mat_path.name,\n",
    "                \"stem\": mat_path.stem,\n",
    "                \"psnr\": psnr.item(),\n",
    "                \"ssim\": ssim.item(),\n",
    "                \"mse\": mse.item(),\n",
    "                \"instruction\": instr_raw\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {mat_path.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Save summary metrics to JSON\n",
    "summary = {\n",
    "    \"total_samples\": len(results),\n",
    "    \"mean_psnr\": np.mean([r[\"psnr\"] for r in results]),\n",
    "    \"mean_ssim\": np.mean([r[\"ssim\"] for r in results]),\n",
    "    \"mean_mse\": np.mean([r[\"mse\"] for r in results]),\n",
    "    \"std_psnr\": np.std([r[\"psnr\"] for r in results]),\n",
    "    \"std_ssim\": np.std([r[\"ssim\"] for r in results]),\n",
    "    \"std_mse\": np.std([r[\"mse\"] for r in results]),\n",
    "    \"run_idx\": run_idx,\n",
    "    \"run_ep\": run_ep,\n",
    "}\n",
    "\n",
    "summary_path = output_dir / \"summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Save detailed results\n",
    "results_path = output_dir / \"detailed_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nInference complete!\")\n",
    "print(f\"Mean PSNR: {summary['mean_psnr']:.2f} +/- {summary['std_psnr']:.2f}\")\n",
    "print(f\"Mean SSIM: {summary['mean_ssim']:.4f} +/- {summary['std_ssim']:.4f}\")\n",
    "print(f\"Mean MSE: {summary['mean_mse']:.6f} +/- {summary['std_mse']:.6f}\")\n",
    "print(f\"Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_root = Path(f\"/home/intern4/fm2026/fm_flow/code_it/logs/{run_idx:05d}_train/inference/ep_{run_ep}\")\n",
    "res_files = sorted(log_root.glob(\"*_result.mat\"))\n",
    "print(f\"Found {len(res_files)} result files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89825e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "print(idx)\n",
    "\n",
    "res_mat = loadmat(res_files[idx])\n",
    "input_img = res_mat[\"input\"].squeeze()\n",
    "output_img = res_mat[\"out\"].squeeze()\n",
    "label_img = res_mat[\"label\"].squeeze()\n",
    "instruction = res_mat[\"instruction\"]\n",
    "\n",
    "x1, x2, y1, y2 = 20, -20, 20, -20\n",
    "\n",
    "vmin_input = np.percentile(input_img, 0.5)\n",
    "vmax_input = np.percentile(input_img, 99.5)\n",
    "vmin_out = np.percentile(output_img, 0.5)\n",
    "vmax_out = np.percentile(output_img, 99.5)\n",
    "vmin_label = np.percentile(label_img, 0.5)\n",
    "vmax_label = np.percentile(label_img, 99.5)\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(input_img[x1:x2, y1:y2], cmap=\"gray\", vmin=vmin_input, vmax=vmax_input)\n",
    "plt.title(\"Input\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(output_img[x1:x2, y1:y2], cmap=\"gray\", vmin=vmin_out, vmax=vmax_out)\n",
    "plt.title(\"Output\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(label_img[x1:x2, y1:y2], cmap=\"gray\", vmin=vmin_label, vmax=vmax_label)\n",
    "plt.title(\"Label\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 4)\n",
    "diff = np.abs(output_img[x1:x2, y1:y2] - label_img[x1:x2, y1:y2])\n",
    "print(output_img.shape, input_img.shape, diff.shape)\n",
    "plt.imshow(diff, cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Output-Label Difference\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e06e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 10 schedule linear t_eps 0.0001\n",
      "out shape: (1, 1, 512, 512)\n",
      "out mse:  0.022062458097934723\n"
     ]
    }
   ],
   "source": [
    "label_exp_temp = label_exp.clone()\n",
    "\n",
    "# Experiment: tweak steps and time scheduling\n",
    "def make_t_schedule(steps, schedule=\"linear\", device=None):\n",
    "    if schedule == \"linear\":\n",
    "        t_vals = torch.linspace(0.0, 1.0, steps + 1, device=device)\n",
    "    elif schedule == \"cosine\":\n",
    "        s = torch.linspace(0.0, 1.0, steps + 1, device=device)\n",
    "        t_vals = 0.5 - 0.5 * torch.cos(torch.pi * s)\n",
    "    elif schedule == \"sigmoid\":\n",
    "        s = torch.linspace(-4.0, 4.0, steps + 1, device=device)\n",
    "        t_vals = torch.sigmoid(s)\n",
    "    else:\n",
    "        raise ValueError(f\"unknown schedule: {schedule}\")\n",
    "    return t_vals\n",
    "\n",
    "def rectified_flow_sample_sched(model, img, text, instruction, steps=10, schedule=\"linear\", t_eps=1e-4):\n",
    "    t_vals = make_t_schedule(steps, schedule=schedule, device=img.device)\n",
    "    z = torch.randn_like(img)\n",
    "    for i in range(steps):\n",
    "        t = t_vals[i].view(1, 1, 1, 1).expand(img.shape[0], 1, 1, 1)\n",
    "        t_next = t_vals[i + 1].view(1, 1, 1, 1).expand(img.shape[0], 1, 1, 1)\n",
    "        x_pred = model.forward(\n",
    "            img=img,\n",
    "            text=text,\n",
    "            use_bottleneck=True,\n",
    "            grad_encoder=True,\n",
    "            instruction=instruction,\n",
    "            flow_xt=z,\n",
    "            flow_t=t.view(img.shape[0], 1),\n",
    "        )\n",
    "        denom = (1.0 - t).clamp_min(t_eps)\n",
    "        v_pred = (x_pred - z) / denom\n",
    "        z = z + (t_next - t) * v_pred\n",
    "    return z\n",
    "\n",
    "steps = 10\n",
    "schedule = \"linear\"  # linear | cosine | sigmoid\n",
    "t_eps = 1e-4\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_exp = rectified_flow_sample_sched(model, img, text, instruction, steps=steps, schedule=schedule, t_eps=t_eps)\n",
    "\n",
    "print(\"steps\", steps, \"schedule\", schedule, \"t_eps\", t_eps)\n",
    "print(\"out shape:\", tuple(out_exp.shape))\n",
    "print(\"out mse: \", torch.mean((out_exp.detach().cpu() - label_exp_temp.detach().cpu()) ** 2).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for steps in [10, 20, 40]:\n",
    "#     for schedule in [\"linear\", \"cosine\", \"sigmoid\"]:\n",
    "#         t_eps = 1e-4\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             out_exp = rectified_flow_sample_sched(model, img, text, instruction, steps=steps, schedule=schedule, t_eps=t_eps)\n",
    "        \n",
    "#         print(\"steps\", steps, \"schedule\", schedule, \"t_eps\", t_eps)\n",
    "#         print(\"out mse: \", torch.mean((out_exp.detach().cpu() - label_exp_temp.detach().cpu()) ** 2).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b350a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full-step vs one-shot metrics on test split\n",
    "# test_root = data_root / \"test\"\n",
    "# test_files = sorted(test_root.glob(\"*.mat\"))\n",
    "# if len(test_files) > 100:\n",
    "#     test_files = test_files[:100] # limit to 100 samples for quicker testing\n",
    "# print(\"test files:\", len(test_files))\n",
    "\n",
    "# full_steps = None  # None uses rectified_flow_sample default\n",
    "# max_samples = None  # set to an int to limit runtime\n",
    "# psnr_full_vals = []\n",
    "# ssim_full_vals = []\n",
    "# mse_full_vals = []\n",
    "# psnr_one_vals = []\n",
    "# ssim_one_vals = []\n",
    "# mse_one_vals = []\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for idx, mat_path in enumerate(test_files):\n",
    "#         if max_samples is not None and idx >= max_samples:\n",
    "#             break\n",
    "#         data = loadmat(mat_path)\n",
    "\n",
    "#         img = torch.from_numpy(data[\"image\"]).unsqueeze(0).unsqueeze(0).float()\n",
    "#         label = torch.from_numpy(data[\"label\"]).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "#         img = interpolate_to_target_width(img, target_size=512)\n",
    "#         img = resize_512(img)\n",
    "#         label = resize_512(interpolate_to_target_width(label, target_size=512))\n",
    "\n",
    "#         img = _normalize_tensor(img)\n",
    "#         label = _normalize_tensor(label)\n",
    "\n",
    "#         text_raw = _coerce_matlab_text(data[\"text\"][0][0])\n",
    "#         instr_raw = _coerce_matlab_text(data[\"instruction\"][0][0])\n",
    "\n",
    "#         text = tokenizer.tokenize(text_raw, context_length=1536).squeeze().unsqueeze(0)\n",
    "#         instruction = tokenizer.tokenize(instr_raw, context_length=1536).squeeze().unsqueeze(0)\n",
    "\n",
    "#         img = img.to(device)\n",
    "#         label = label.to(device)\n",
    "#         text = text.to(device)\n",
    "#         instruction = instruction.to(device)\n",
    "\n",
    "#         if full_steps is None:\n",
    "#             out_full = rectified_flow_sample(model=model, img=img, text=text, instruction=instruction)\n",
    "#         else:\n",
    "#             out_full = rectified_flow_sample(model=model, img=img, text=text, instruction=instruction, steps=full_steps)\n",
    "#         out_oneshot = rectified_flow_sample(model=model, img=img, text=text, instruction=instruction, steps=1)\n",
    "\n",
    "#         psnr_full = calculate_psnr(out_full, label)\n",
    "#         ssim_full = calculate_ssim(out_full, label)\n",
    "#         mse_full = torch.mean((out_full - label) ** 2)\n",
    "\n",
    "#         psnr_one = calculate_psnr(out_oneshot, label)\n",
    "#         ssim_one = calculate_ssim(out_oneshot, label)\n",
    "#         mse_one = torch.mean((out_oneshot - label) ** 2)\n",
    "\n",
    "#         psnr_full_vals.append(psnr_full.item())\n",
    "#         ssim_full_vals.append(ssim_full.item())\n",
    "#         mse_full_vals.append(mse_full.item())\n",
    "#         psnr_one_vals.append(psnr_one.item())\n",
    "#         ssim_one_vals.append(ssim_one.item())\n",
    "#         mse_one_vals.append(mse_one.item())\n",
    "\n",
    "#         if (idx + 1) % 20 == 0:\n",
    "#             print(\"processed\", idx + 1)\n",
    "\n",
    "# if psnr_full_vals:\n",
    "#     print(f\"full-step PSNR: {np.mean(psnr_full_vals):.2f} +/- {np.std(psnr_full_vals):.2f}\")\n",
    "#     print(f\"one-shot PSNR: {np.mean(psnr_one_vals):.2f} +/- {np.std(psnr_one_vals):.2f}\")\n",
    "#     print(f\"delta PSNR (full - one): {np.mean(np.array(psnr_full_vals) - np.array(psnr_one_vals)):.2f}\")\n",
    "#     print(f\"full-step SSIM: {np.mean(ssim_full_vals):.4f} +/- {np.std(ssim_full_vals):.4f}\")\n",
    "#     print(f\"one-shot SSIM: {np.mean(ssim_one_vals):.4f} +/- {np.std(ssim_one_vals):.4f}\")\n",
    "#     print(f\"delta SSIM (full - one): {np.mean(np.array(ssim_full_vals) - np.array(ssim_one_vals)):.4f}\")\n",
    "#     print(f\"full-step MSE: {np.mean(mse_full_vals):.6f} +/- {np.std(mse_full_vals):.6f}\")\n",
    "#     print(f\"one-shot MSE: {np.mean(mse_one_vals):.6f} +/- {np.std(mse_one_vals):.6f}\")\n",
    "#     print(f\"delta MSE (full - one): {np.mean(np.array(mse_full_vals) - np.array(mse_one_vals)):.6f}\")\n",
    "# else:\n",
    "#     print(\"no test samples found in\", test_root)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
